---
title: "Assignment A0-A1"
author: "Shreysa Sharma"
date: "9/20/2017"
output:
  html_document: default
  pdf_document: default
---

### Introduction

This report attempts to answer the following questions:
1). Explain the difference in the execution profiles among variants;
2). Comment on the differences in performance of the sequential and parallel/concurrent variants;
3). Comment on the impact of the number of executor threads on performance;
4). Explain which implementation variant and configuration have the best combination of performance and stability.

Apart from the results of the evaluation the report should include the specs of the execution environment (Java version, OS version, relevant hardware specs) and a summary description of the design of the evaluated programs.


#### Specifications of Execution Environment
Attribute                         | Value
----------------------------------|-------------------------------
Java Version                      | 1.8.0_102
Java(TM) SE Runtime Environment   | (build 1.8.0_102-b14)
Java HotSpot(TM) 64-Bit Server VM | (build 25.102-b14, mixed mode)
Model Identifier                  |	MacBookPro11,2
Processor Name                    |	Intel Core i7
Processor Speed                   |	2.2 GHz
Number of Processors              |	1
Total Number of Cores             |	4
L2 Cache (per Core)               |	256 KB
L3 Cache                          |	6 MB
Memory                            | 16 GB




### Summary of the design of evaluated program

The current implementation has 2 variants, one is serial and the other is parallel/multithreaded.
In the multithreaded variant, the application first assigns files to the threads, then the files are processed parallelly by the specified number of threads where it keeps track of letter ocurrances and inserts words along with it's k-neighborhoods into a hashmap, then all the data from these various hashmaps and letter ocurrances is accumulated into a global data structure, the letter scores, word scores, k-neighborhood scores and k-neighborhood mean scores are computed and sorted on a single thread and sent out to an output file. 

#### Collected results from performance evaluations
##### Table 1: K = 2, Threads = 1-16 (timings averaged across 3 runs per variant)

```{r}
library(ggplot2)
performance_data_k2<-read.csv("output/results_kval_2_speed_up.csv")
knitr::kable(performance_data_k2)
```

The above table contains data collected by running the program 3 times with threads range (1, 16) and K value as 2. As mentioned above in the summary of design, the program processes the files on different number of threads, then the data is accumulated and then computation of      various scores is done. The columns processing_avg_s, accumulate_avg_s and compute_avg_s
respectively represent this data. The total_avg_s is nothing but sum of data in all 3           columns. According to Amdahl's law the speed up of a program for the same work (i.e the same problem with same input) is the time taken by the program when it is run sequentially divided by time taken by the program when it is run parallelly. Therefore, the columns processing_speed_up, accumulate_speed_up and compute_speed_up represent the speed up of the various parts of the program.

```{r}
ggplot(performance_data_k2, aes(x=num_threads, y=processing_speed_up, color="processing")) + 
  geom_line() + geom_point() +
  ylab("Speed Up (compared to serial version)") + 
  xlab("Number of threads") + 
  scale_y_continuous(breaks=seq(0,16,2), limits = c(0,16)) + 
  scale_x_continuous(breaks=seq(0,16,2), limits = c(0,16)) +
  geom_line(aes(x=num_threads, y=num_threads, colour="ideal")) +
  geom_point(aes(x=num_threads, y=num_threads, colour="ideal")) +
  geom_line(aes(x=num_threads, y=compute_speed_up, colour="compute")) +
  geom_point(aes(x=num_threads, y=compute_speed_up, colour="compute")) +
  geom_line(aes(x=num_threads, y=total_speed_up, colour="total")) +
  geom_point(aes(x=num_threads, y=total_speed_up, colour="total")) +
  labs(title="Plot 1: Speed-up - Ideal vs Real (k = 2)")
```

Plot 1 provides a graphical representation of data shown in table 1. The light green curve which is at a 45 degree angle to x axis shows how the speed up should be as the number of threads increase ideally. the other 3 curves represent the processing speed up, compute speed up and total speed up. 

As per Amdahl's law, the theoretical speedup in latency of the execution of a program in function of the number of processors executing it, for different number of threads/processors. The speedup is limited by the serial part of the program. For example, if 95% of the program can be parallelized, the theoretical maximum speedup using parallel computing would be 20 times, likewise if 50% of the program can be parallelized - the therotical maximum speedup using parallel computing would be 2 times the time taken by serial version. Plot 2 thereby signifies the same speed up representations. (Answer to point 2 in assignment)
(Above statement taken from https://en.wikipedia.org/wiki/Amdahl%27s_law)

Looking at plot 1 it is clear that the time taken by the threaded version of the program in the current implementation, if not at a great scale but is definitely less than the time taken by the sequential program.(Answer to point 1 in the assignment)


```{r}
ggplot(performance_data_k2, aes(x=num_threads, y=processing_speed_up, color="processing")) + 
  geom_line() + geom_point() +
  ylab("Speed Up (compared to serial version)") + 
  xlab("Number of threads") + 
  scale_y_continuous(breaks=seq(0,3,0.25)) + 
  scale_x_continuous(breaks=seq(0,16,1), limits = c(0,16)) +
  geom_line(aes(x=num_threads, y=compute_speed_up, colour="compute")) +
  geom_point(aes(x=num_threads, y=compute_speed_up, colour="compute")) +
  geom_line(aes(x=num_threads, y=total_speed_up, colour="total")) +
  geom_point(aes(x=num_threads, y=total_speed_up, colour="total")) +
  labs(title="Plot 2: Speed-up vs Num Threads (k = 2)")
```

Plot 2 represents the processing speed up, compute speed up and compute speed up plotted against number of threads when K value is 2. It is clear that the threaded version performs better than the serial version of the program but also that addition of more threads will give reduced performance as JVM will schedule multiple threads to the same physical core so for best performance threads should be equal to number of cores. (Answer to point 3 in assignment)

##### Table 2: K = 4, Threads = 1-16 (timings averaged across 3 runs per variant)

```{r}
library(ggplot2)
performance_data_k4<-read.csv("output/results_kval_4_speed_up.csv")
knitr::kable(performance_data_k4)
ggplot(performance_data_k4, aes(x=num_threads, y=processing_speed_up, color="processing")) + 
  geom_line() + geom_point() +
  ylab("Speed Up (compared to serial version)") + 
  xlab("Number of threads") + 
  scale_y_continuous(breaks=seq(0,16,2), limits = c(0,16)) + 
  scale_x_continuous(breaks=seq(0,16,2), limits = c(0,16)) +
  geom_line(aes(x=num_threads, y=num_threads, colour="ideal")) + 
  geom_point(aes(x=num_threads, y=num_threads, colour="ideal")) + 
  geom_line(aes(x=num_threads, y=compute_speed_up, colour="compute")) +
  geom_point(aes(x=num_threads, y=compute_speed_up, colour="compute")) +
  geom_line(aes(x=num_threads, y=total_speed_up, colour="total")) +
  geom_point(aes(x=num_threads, y=total_speed_up, colour="total")) +
  labs(title="Plot 3: Speed-up - Ideal vs Real (k = 4)")
```

The above table contains data collected by running the program 3 times with threads range (1, 16) and K value as 4.

```{r}
ggplot(performance_data_k4, aes(x=num_threads, y=processing_speed_up, color="processing")) + 
  geom_line() + geom_point() +
  ylab("Speed Up (compared to serial version)") + 
  xlab("Number of threads") + 
  scale_y_continuous(breaks=seq(0,3,0.25)) + 
  scale_x_continuous(breaks=seq(0,16,1), limits = c(0,16)) +
  geom_line(aes(x=num_threads, y=compute_speed_up, colour="compute")) +
  geom_point(aes(x=num_threads, y=compute_speed_up, colour="compute"), shape=15) +
  geom_line(aes(x=num_threads, y=total_speed_up, colour="total")) +
  geom_point(aes(x=num_threads, y=total_speed_up, colour="total"), shape=17) +
  labs(title="Plot 4: Speed-up vs Num Threads (k = 4)")
```

Plot 4 represents the processing speed up, compute speed up and compute speed up plotted against number of threads when K value is 4. since each thread is reading file from hard disk we have multiple threads reading at the same time because of which the performance could also degrade as disk I/O bandwidth could be full. it is unlikely in this case as the total size of the dataset is of the order 71 mb and current internal drive/SSDbandwidth is greater than that but for large datasets it could cause a problem.

``` {r}
performance_data_k2<-read.csv("output/results_kval_2_speed_up.csv")
performance_data_k4<-read.csv("output/results_kval_4_speed_up.csv")
ggplot() + 
  geom_line(data=performance_data_k4, aes(x=num_threads, y=processing_avg_s, color="processing_k4")) +
  geom_point(color="red") +
  geom_line(data=performance_data_k4, aes(x=num_threads, y=compute_avg_s, color="compute_k4")) +
  ylab("Time taken in seconds") + 
  xlab("Number of threads") + 
  scale_x_continuous(breaks=seq(1,16,1), limits = c(1,16)) +
  geom_line(data=performance_data_k2, aes(x=num_threads, y=processing_avg_s, colour="processing_k2")) + 
  geom_line(data=performance_data_k2, aes(x=num_threads, y=compute_avg_s, colour="compute_k2")) + 
  labs(title="Plot 5: Comparison between k = 2 & k = 4 runs")
```

Plot 5 represents the processing time (dark green for k =2 and purple for k=4) and compute time (orange for k=2 and light green for k=4) for threads 1 to 16. This clearly signifies that as the K value increases, in the current implementation, the time taken by sequential and threaded program would increase but the serial part of the program would increase by a greater extent. 

The current implementation of this problem assigns complete dataset to the specified number of threads, hence, the results of the dataset are retained in the memory in 1 go. Since, we have just 100 files this program runs fine but when we have million files it'll take up memory then we need to process the data in batches. Batch size is limited by the available memory.

The program also has a section that implements a trivial load balance strategy where we find out the total size of the dataset and depending on the number of threads we allocate a certain size of work to each thread. 

Looking at table 1 and 2, it is clear that the multithreaded variant with threads 11 and k value 2 has the best combination of performance and stability.(Answer to point 4 in assignment)

### Conclusion

During the completion of this assignment, it has become clear that implementation of a threaded program requires deeper understanding of threads, paarllel programming algorithms, synchronization methods, load balancing, the programming language itself, the memory and I/O bandwidths and so on. Depending upon the problem, different approaches can be considered that suit the problem in question. This increases the complexity and maintainability of the code making it difficult to deploy widely. The benefit of a framework which abstracts away these underlying parameters and provides the developer with a simpler API to deal with is obvious. As we can observe over the last few years HADOOP, SPARK etc. have taken over the industry and made it easier for developers to solve ever more difficult problems on very large datasets without worrying about most of the above complexities.